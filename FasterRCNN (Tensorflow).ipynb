{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \"\"\" Helper function for loading in our image path\"\"\"\n",
    "    \n",
    "    bits = tf.io.read_file(path)\n",
    "    img = tf.io.decode_jpeg(bits, channels=3)\n",
    "    img = tf.cast(img, dtype=tf.float32)/255.\n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_boxes(img, boxes, class_names, scores, threshold=0.3, use_cv=True):\n",
    "\"\"\"Function for drawing our bounding boxes once given the image and faster rcnn's outputs\"\"\"\n",
    "\n",
    "    # color for each class\n",
    "    colors = np.random.uniform(0,1, size=(len(class_names), 3))\n",
    "    img = img.numpy()\n",
    "    if use_cv: # if using opencv to show the picture it needs to be converted to BGR channel format\n",
    "        img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    (h,w) = img.shape[:2]\n",
    "    for i in range(boxes.shape[0]):\n",
    "        color = colors[i]\n",
    "        if scores[i] >= threshold: # Only draw boxes where the confidence is higher than our threshold\n",
    "            box = boxes[i] * np.array([h,w,h,w])\n",
    "            (yi,xi,yj,xj) = box.astype(\"int\") # Remember faster rcnn's output for bounding box coorindates are \n",
    "                                              # (ymin, xmin, ymax, xmax) not yolo's (xmin, ymin, xmax, ymax)\n",
    "            \n",
    "            # Drawing the rectangle and text on image\n",
    "            cv.rectangle(img, (xi,yi), (xj,yj), color,2)\n",
    "            y_text = yi-15 if yi-15>15 else yi+15\n",
    "            label = f\"{str(class_names[i])[1:]}: {(scores[i]*100):.2f}\"\n",
    "            cv.putText(img, label, (xi,y_text), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class f_rcnn():\n",
    "    def detect_image(path):\n",
    "        \"\"\"Function meant to detect a single image at a time.\"\"\"\n",
    "        \n",
    "        img = load_image(path)\n",
    "        converted_image = img[tf.newaxis, ...]\n",
    "        result = detector(converted_image)\n",
    "        result = {key:value.numpy() for key,value in result.items()} \n",
    "        redrawn_img = draw_boxes(img, result[\"detection_boxes\"], result[\"detection_class_entities\"],\n",
    "                   result[\"detection_scores\"], threshold=0.3,use_cv=True)\n",
    "        cv.imshow(\"Image\",redrawn_img)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()\n",
    "    \n",
    "    def detect_video(path):\n",
    "        \"\"\"As the name implies this function is meant to be run on video.\"\"\"\n",
    "        \n",
    "        cap = cv.VideoCapture(path)\n",
    "        while True:\n",
    "            _,img = cap.read()\n",
    "            img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "            converted_image = img[tf.newaxis, ...]\n",
    "            result = detector(converted_image)\n",
    "            result = {key:value.numpy() for key,value in result.items()}\n",
    "            img = draw_boxes(img, result[\"detection_boxes\"], result[\"detection_class_entities\"],\n",
    "                       result[\"detection_scores\"], threshold=0.3, use_cv=True)\n",
    "            cv.imshow(\"Vid\", img)\n",
    "            if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Download model from tf hub\n",
    "model_link = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "detector = hub.load(model_link).signatures[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rcnn.detect_image(\"images/busyStreet2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rcnn.detect_video(\"/home/walt/Videos/CarFootage.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
